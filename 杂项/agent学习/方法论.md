# Agent 方向学习规划 - 求职与方法论

最后更新：2026-01-17
返回索引：[agent方向的规划.md](./agent方向的规划.md)

---

## 求职与方法论

### 4. 项目作品集建议（从易到难）

1) 前端“学习助理”Agent（工具调用）
- 输入：学习目标/时间/约束；输出：周计划 + 每日任务卡片
- 亮点：任务拆解、可视化执行轨迹、失败重试与降级策略

2) 个人知识库 RAG（文档助手）
- 输入：项目/课程资料；输出：带引用的答案 + 相关片段 + 置信/不确定提示
- 亮点：可追溯、可更新、离线用例集回归

3) 浏览器工作流 Agent（前端强相关）
- 输入：“帮我把某网站的公开信息整理成表格/总结”
- 工具：Playwright（或浏览器扩展）+ 结构化抽取
- 亮点：把“前端自动化 + Agent”结合成可演示的工作流产品

### 5. 面试表达素材（建议准备）

- 你如何控制 Agent 的边界（白名单工具、权限隔离、超时/重试、拒答策略）
- 你如何降低幻觉（RAG + 引用、先检索后回答、结构化输出校验）
- 你如何评估效果（用例集、自动回归、指标与可观测性）
- 你如何做工程权衡（成本/延迟/稳定性/可维护性）

---

### 19. 求职导向：前端如何系统学 Agent（更容易写进简历）

#### 19.1 你要“学会的”不是 Agent 概念，而是可交付的产品能力
面向秋招，最能打动面试官的不是“我用过 LangChain/xx 框架”，而是你能把模型能力做成“可用、可控、可验证”的产品闭环。对你（前端 + AI）来说，核心是两条线并行：
- 产品落地线（前端强项）：流式对话/生成、多人机交互的任务流、多步表单、上传与预览、地图交互、编辑器、分享页、错误提示与引导
- 工程治理线（后端最小闭环，但你要懂）：鉴权、限流、日志、成本、重试、工具白名单、结构化输出校验、数据/文件存储、可观测与回归

你可以把它理解为：“我不是做聊天机器人，我是在做一个带 AI 能力的产品”。只要能上线可用、体验顺滑、可追踪可复现，哪怕功能不多，也足够成为简历亮点。

#### 19.2 前端 vs 后端学 AI 的侧重点差异（你该怎么取舍）

前端侧重点（体验与可控交互）：
- 交互形态：把 Agent 的过程变成用户看得懂、能介入的流程（确认/选择/编辑/回退），而不是一次性输出
- 信息组织：让输出结构化（卡片、清单、时间线、地点地图、引用片段），降低“看不懂/不信任”的成本
- 失败可用：空状态、无 GPS、无权限、模型报错时的降级路径与引导（用户仍然能完成任务）
- 结果可二次加工：编辑、版本、对比、导出（Markdown/图片）、分享（公开链接）
- 可视化可信度：显示“我基于什么生成的”（EXIF、地点、笔记片段、用户输入）+ 轨迹（计划→工具→结果）

后端侧重点（可靠性与治理）：
- 受控 Agent：工具白名单 + 参数校验 + 权限隔离（哪些数据能读、哪些能写）
- RAG 管线：分块、召回、重排序、引用与更新（不是“塞一堆文档”）
- 稳定性：超时、重试、熔断、降级、缓存（尤其是地理/天气等重复查询）
- 成本与延迟：token 统计、限额、并发限制、结果缓存、按用户/按功能计费（哪怕 MVP 只是记录）
- 观测与评估：请求日志、工具调用轨迹、错误聚类、用例集回归（至少 20 条）

对你来说的最佳策略：
- 你不需要一开始把后端做成“企业级平台”，但必须把“治理的关键点”做出最小实现（能解释、能验证）
- 简历写法要避免“调用 API”，而是强调“受控工具调用 + 可观测 + 可评估 + 可上线”

#### 19.3 学习路径（前端 + Agent 的最短闭环）

建议把学习拆成 5 个层级，每一层都有“可演示产物”：
1) L0：React/Next.js 基础（路由、数据请求、状态管理、表单、组件化、基础工程）  
2) L1：LLM 接入（服务端转发、流式输出、错误处理、会话上下文）  
3) L2：受控工具调用（白名单工具、结构化输出、校验与重试、轨迹可视化）  
4) L3：RAG（只在你需要“基于资料回答”时再上；必须带引用与可追溯）  
5) L4：评估与运营（用例集回归、指标面板、成本/延迟、灰度与降级）

你现在的 PhotoCoach Agent，天然可以覆盖 L1-L4（且和前端交互强相关），是非常适合秋招的主项目。

---

### 20. PhotoCoach Agent 如何“像 Agent”而不是“像聊天”

把它设计成“工作流编排器（Workflow Orchestrator）”，每一步都可验证、可回退、可继续：
1) 导入照片（多张）  
2) 工具：解析 EXIF（时间/镜头/相机/GPS）→ 结构化结果  
3) 若无 GPS：Agent 产出候选地点/区域（给理由与不确定性）→ 用户确认“是/否”  
4) 否：地图搜索 → 定位 → 拖拽微调 → 逆地理编码 → 用户确认  
5) 形成地点卡片（地点名/坐标/时间范围/照片集合/用户备注）  
6) Agent：生成“去过的地方总结”（按风格）→ 输出 Markdown（可编辑）→ 导出/分享  
7) Agent：生成“下次拍摄规划清单”（可勾选/收藏/复用）

关键点：每一步输出都要求“结构化”（例如 JSON Schema），并且在 UI 上有“确认/编辑”入口，让用户成为闭环的一部分，这就是产品化 Agent 的核心。

---

### 21. 技术亮点怎么写进简历（可量化、可验证、可复述）

#### 21.1 受控工具调用（最重要）
- 工具白名单：EXIF 解析、坐标转换、AMap 搜索/逆地理编码、用户笔记检索、总结生成
- 参数校验：对模型输出做 JSON Schema 校验，失败则自动纠错/重试/回退到手动流程
- 权限边界：公开可见 ≠ 可任意写入；上传/删除必须登录；公开分享只读

#### 21.2 结构化输出 + 前端可视化
- 结构化产物：地点卡片、照片列表、总结 Markdown、规划清单（都可保存/复用）
- 轨迹与日志面板：展示“计划→调用了哪些工具→得到哪些中间结果→最终生成了什么”

#### 21.3 稳定性与成本（面试常问）
- 重试与降级：模型失败/地图失败/无 GPS 时仍可完成任务（用户体验不中断）
- 成本记录：按功能统计 token/耗时（哪怕是 MVP 也能展示你有成本意识）
- 缓存策略：地理/逆地理编码/天气等重复请求做缓存，提升速度并降低费用

#### 21.4 评估与回归（拉开差距）
- 用例集：至少 20 条（有 GPS/无 GPS、多地点、多照片、不同风格输出、不同输入质量）
- 回归方式：每次改 Prompt/工具/模板后跑一遍（正确性、结构完整性、失败率、耗时）

---

### 22. 业务思考怎么体现（你“像产品/像业务”）

建议你把业务思考写成一页“产品说明”（README 或 wiki），面试时能讲清楚：

#### 22.1 用户画像与场景
- 摄影爱好者：拍了很多照片但难以整理与复盘
- 旅行记录者：希望快速生成“可发布的总结”，并可持续沉淀地点与经验

#### 22.2 指标（你做了什么、怎么证明有效）
- 导入成功率（照片上传/EXIF 解析成功率）
- 地点确认耗时（从导入到地点卡片确认的时间）
- 生成后编辑率（越高说明你做的是“可编辑的初稿”，符合真实工作流）
- 分享率/导出率（结果是否真的可用）
- 留存（同一用户重复使用的次数/周期）

#### 22.3 关键取舍（为什么这么做）
- 无 GPS：不强行“猜对”，而是给候选 + 让用户确认 + 提供手动兜底（降低幻觉伤害）
- 公开分享：让传播与展示更方便，但写入操作必须鉴权，并提示隐私（位置暴露风险）
- “Agent 不直接替你做决定”：Agent 提供建议与草稿，用户做最终确认与编辑（可控、可信）

#### 22.4 风险与边界（大厂很看重）
- 防滥用：公开分享不代表开放上传；对接口做限流；对大图做大小限制
- 隐私提示：公开分享会暴露地点/时间信息，需提示与可删除

---

### 23. 更底层的 Agent 学习：从“黑箱聊天”到“可控系统”

#### 23.1 先建立一个正确心智模型：LLM 不是“智能体”，它是“概率型代码生成器”
你可以把 LLM 当成一个“在自然语言里工作的 CPU”，但它有几个硬限制：
- **它不会持续思考**：模型每次只是在生成下一段 token；所谓“思考链”只是输出的一种形式，不等于真实执行。
- **它没有真实记忆**：它只能看到你喂给它的上下文（context window）。所谓“记忆”必须由你在系统里实现（数据库/向量库/缓存）。
- **它不会访问现实世界**：所有“看照片/查地点/存数据”的能力都要通过工具调用（tools）接到真实系统上。

因此，真正的 Agent 不是“让模型更聪明”，而是：
> 用工程手段把 LLM 包起来：给它目标、状态、工具、边界、反馈，让它在一个可控的闭环里工作。

#### 23.2 Agent 的最小闭环（Sense → Plan → Act → Observe → Iterate）
一个能工作的 Agent 系统，至少要包含这些“可实现的部件”：
1) **状态 State**：当前任务进度、已收集的信息、用户确认结果、失败原因  
2) **规划 Plan**：下一步要做什么（并不是长篇宏大计划，而是可执行的“下一步”）  
3) **动作 Act**：调用工具/生成结构化输出/提示用户确认  
4) **观察 Observe**：工具返回值、用户反馈、校验结果  
5) **迭代 Iterate**：失败重试/改写参数/换工具/回退到手动路径

你做产品时，建议把它显式地做成“状态机”：
- 每一步都有输入、输出、失败分支、可回退点
- 用户确认是“状态转移条件”，不是聊天中的一句话

#### 23.3 “受控”是 Agent 的灵魂：把模型当作不可信组件
大厂更看重你有没有“工程边界意识”。核心做法：
- **工具白名单**：模型只能调用你给的工具集合，不能随便发请求/读写敏感数据
- **参数校验**：模型输出必须通过 JSON Schema（或 zod）校验；不通过就拒绝执行或触发修复
- **权限隔离**：公开页面只读；写操作必须鉴权；服务端密钥永远不下发到浏览器
- **幂等性**：同一个请求重复执行不应该造成重复写入（避免重试导致脏数据）

你可以把“Agent 是否靠谱”理解为：系统是否能在模型犯错时仍然不出大事故，并能引导用户完成目标。

---

### 24. “工具调用”更底层的设计：工具接口决定上限

#### 24.1 好工具的标准：可测试、可校验、可观测、可复用
每个工具都应该像一个严格的 API：
- 输入参数明确（类型/范围/必填）
- 输出结构稳定（可被 UI 直接消费）
- 错误可分类（可重试/不可重试/需要用户）
- 记录耗时与结果摘要（用于追踪与成本优化）

对 PhotoCoach Agent 来说，你至少会有这些工具（示例拆分方式）：
- `extract_exif(photoUrl|file)` → `{ takenAt, camera, lens, gpsWgs84? }`
- `wgs84_to_gcj02(lat, lng)` → `{ lat, lng }`
- `amap_poi_search(keyword, city?, locationBias?)` → `{ candidates[] }`
- `amap_reverse_geocode(latGcj, lngGcj)` → `{ formattedAddress, poi? }`
- `save_place(placeDraft)` / `save_trip(tripDraft)`（服务端鉴权）
- `render_markdown(template, data)`（生成可编辑初稿）

#### 24.2 为什么必须结构化输出（JSON Schema）
结构化输出解决的是“模型输出不可控”的根因：
- 你可以 **验证**：字段缺失/类型错误立即发现
- 你可以 **回填 UI**：卡片/表单/地图点位都来自结构化字段
- 你可以 **做回归测试**：对比字段变化，而不是肉眼看一段文案

文案生成（小红书风/旅行日志）仍然可以是 Markdown，但建议“外层结构化、内层自由文本”：
- 外层：`{ title, summary, highlights[], pitfalls[], next_time_tips[], markdown }`
- 内层：`markdown` 字符串

#### 24.3 失败分类（你要能讲出来）
面试时非常加分的点：你能把失败分成 3 类并处理：
1) **工具失败**：地图 API 超时/限流 → 重试/缓存/降级  
2) **模型失败**：输出不符合 schema/内容跑偏 → 纠错提示/降低温度/拆步  
3) **数据不足**：无 GPS/无行程信息 → 进入“用户确认/手动补全”流程  

---

### 25. 记忆与 RAG：把“上下文”工程化

#### 25.1 你需要区分三种“记忆”
1) **会话记忆（短期）**：本次对话/本次操作的上下文（放在服务端 session 或数据库）  
2) **用户画像（长期）**：偏好（风格、常去城市、器材、常用镜头）  
3) **知识库（可检索）**：摄影笔记、地点攻略、历史总结（适合向量检索）  

#### 25.2 RAG 不是“加个向量库”，而是一条检索-生成流水线
最小可用的 RAG（足以做简历亮点）包含：
- 文档分块（chunk）：按语义切分，保留标题/来源/时间等元数据
- 召回（retrieve）：向量检索 + 关键词检索（可选）
- 重排序（rerank）：把最相关的片段排到前面（没 rerank 也行，但要能解释取舍）
- 生成（generate）：强制引用（给出引用片段 ID/来源），并在 UI 展示
- 更新策略：新增/替换/删除笔记时同步更新索引

你可以在 PhotoCoach Agent 里把 RAG 用在两件事上：
- “地点总结”引用：引用你自己的笔记片段或历史总结（提升可信度）
- “规划清单”引用：引用器材清单与过往经验（更个性化）

#### 25.3 反直觉但重要：不要把所有东西都塞进上下文
上下文越长 ≠ 越聪明，反而会：
- 变慢、变贵、变乱
- 更容易被无关信息干扰
正确做法是“少量高相关 + 可追溯引用 + 用户可编辑确认”。

---

### 26. 评估与迭代：你和大多数同学拉开差距的地方

#### 26.1 建一个“可复现的用例集”（你未来会感谢现在的自己）
用例集不需要复杂，关键是覆盖真实分支：
- 有 GPS / 无 GPS
- 关键词搜索准确 / 不准确
- 用户确认是 / 否
- 小红书风 / 旅行日志
- 多地点多照片

每条用例记录：
- 输入（照片/地点/行程/偏好）
- 期望输出结构（字段必须齐全）
- 允许差异范围（文案不要求逐字一致，但结构与要点要一致）

#### 26.2 指标（让你更像“能上线的人”）
建议从一开始就记录（哪怕先写到日志里）：
- 延迟：首 token 时间、总耗时
- 成本：token 数/次数（按用户、按功能）
- 失败率：schema 校验失败、工具失败、用户放弃率
- 成功率：地点确认成功率、导出率、分享率

#### 26.3 Prompt 不是玄学：把它当“可版本化的配置”
建议你从 Day 1 就做到：
- Prompt 版本号（v1/v2）
- 变更记录（改了什么、为什么）
- 回归对比（改 prompt 前后，用例集跑一遍）

这样面试时你可以讲：
> 我不是“调一调 prompt”，我是用工程方式迭代一个可控系统。

---

### 27. 大厂通用打法：你不确定投哪家时，做“最大公约数”

你现在“不知道投哪家”完全没问题。大厂通用偏好是相似的：
- **React/Next.js + TypeScript**：主流前端栈
- **端到端交付**：能上线、能运维、能解释取舍
- **可靠性意识**：鉴权、限流、日志、错误分级、降级路径
- **评估意识**：用例集、指标、成本/延迟

你的项目如果能做到：
1) 真实工作流（导入→确认→生成→编辑→分享）  
2) 受控工具调用（schema + 白名单 + 权限）  
3) 可观测可评估（轨迹 + 指标 + 用例回归）  
它就能“适配多数大厂面试官的评价框架”。


---

### 附录 A：更底层更深入的 Agent 学习笔记（前端向）

> 目标：把“听说过 Agent 但一头雾水”的状态，推进到“能设计、能实现、能解释、能评估”的工程能力。

#### A0. 先把名词对齐（否则越学越乱）

- `LLM`：生成 token 的模型，本身不具备执行能力与记忆。
- `Tool`：你写的受控函数/API，让系统能读 EXIF、查地图、存数据库、检索文档。
- `Agent/Orchestrator`：控制器，决定何时问用户、何时调用哪个工具、何时生成结果。
- `Memory`：状态与长期信息的存储与检索（DB/缓存/向量库），不是“把历史全塞 prompt”。
- `RAG`：检索增强生成（Retrieve-then-Generate），本质是一条检索流水线，不是“装个向量库”。
- `Evaluation`：用例集 + 指标 + 回归，让效果能被讨论与复现。

你会发现：真正“像 Agent”的系统，至少由 3 层组成：
1) 控制器（状态机/工作流）  
2) 工具层（严格 API）  
3) 记忆层（可持久化、可检索）  

---

### 附录 B：工具调用（Function Calling）与 JSON Schema（把模型拴住）

#### B1. 你要解决的根问题：模型输出的不可控性
模型最危险的不是“答错”，而是：
- 给出看似合理但不可验证的内容（幻觉）
- 输出结构不稳定导致前端/工具执行崩溃
- 在不该写入的时候写入（权限边界被突破）

所以你的系统要把模型当作“不可信组件”：
- 只允许在白名单工具里行动
- 只接受通过 schema 校验的参数
- 把敏感执行放在服务端，并做鉴权与审计

#### B2. Schema 设计的工程范式（建议你照着做）

原则 1：字段越少越好，但必须覆盖 UI/流程需要的“控制字段”
- 例：地点确认需要 `confidence`、`candidates[]`、`reasoning_summary`
- 例：总结需要 `highlights[]`、`pitfalls[]`、`next_tips[]`、`markdown`

原则 2：枚举优先于自由文本
- 风格：`xiaohongshu | travel_log`
- 操作：`ask_user_confirm | call_tool | finalize`

原则 3：把“可选自由文本”放在最后一个字段（避免污染结构）
- `markdown` 可以自由，但外层结构必须稳定

原则 4：输入输出都要有版本号
- `schema_version: "v1"`
- 后面改字段时你能兼容旧数据、能跑回归

#### B3. 工具颗粒度：别太大，也别太碎
经验法则：一次工具调用完成一件“可测试的事”。
- 太大：`generate_everything()` → 不可控、不可测、不可复用
- 太碎：每个字段都一个工具 → 交互成本高、延迟高

PhotoCoach 常见工具拆分（建议）：
- 确定性工具：EXIF 解析、坐标转换、Markdown 渲染
- 外部依赖工具：AMap 搜索、逆地理编码
- 写入工具：保存地点/照片集合/总结（必须鉴权）

#### B4. 参数校验失败后的“自修复回路”（非常加分）
你可以实现一个简单但有效的闭环：
1) 模型输出 JSON  
2) schema 校验失败 → 生成“错误摘要”（缺字段/类型错/越界）  
3) 把错误摘要回喂模型：只允许它修复 JSON（不允许重写任务）  
4) 连续失败 2 次 → 回退为“让用户补信息/手动流程”  

你能把这套讲清楚，面试官基本会默认你具备“可上线思维”。

#### B5. 工具调用的安全边界（必须掌握）
- 服务端密钥（如 `SERVICE_ROLE_KEY`）永远不出服务端
- 公开不等于可写：公开页面可读，写操作要登录 + 限流
- 危险动作（删除/发布覆盖）二次确认（最好由前端确认按钮触发，不由模型自作主张）
- 工具层拒绝“把文档内容当指令”（prompt injection 防护的最后防线）

---

### 附录 C：RAG 全链路（从“能答”到“可信、可追溯”）

#### C1. 什么时候上 RAG（别为了简历硬上）
你上 RAG 的理由必须是“需求驱动”：
- 要个性化（基于你的笔记/器材/历史地点）
- 要引用依据（提升可信度、减少幻觉）
- 要可更新（知识会变，不能每次手工改 prompt）

如果需求只是通用建议，先用工具调用 + 状态机就足够。

#### C2. 最小 RAG：你应该能画出这张流程图并实现简化版
`Ingest → Chunk → Embed/Index → Retrieve → (Rerank) → Compose Context → Generate w/ Citations → Log/Eval`

其中每一步你都要回答一个“工程问题”：
- Chunk：切多大？怎么保留来源？
- Retrieve：topK 取多少？要不要混合检索（关键词 + 向量）？
- Context：怎么把检索结果拼进 prompt 才不污染指令？
- Citations：怎么把引用返回给 UI 展示？
- Update：新增/删除笔记如何同步索引？

#### C3. Chunking（切分）深水区：为什么它决定召回上限
你可以用三个维度来调：
- 语义完整性：一个 chunk 能表达完整观点吗？
- 可定位性：引用时用户能快速回到原文吗？
- 成本：chunk 越多索引越大，检索越慢

摄影笔记很实用的策略：
- 先按标题/小节切（自然结构）
- 超长小节再按段落切
- 每个 chunk 附带元数据：城市、景点、题材、镜头、时间范围、标签

#### C4. Hybrid Search（混合检索）很适合“地名/器材型号”
向量检索擅长语义，但地名/型号/专有名词经常关键词更准。
因此你可以做：
- 先关键词过滤（city/location/gear）
- 再向量召回（更省、更准）

#### C5. 引用（citations）是你区别于“聊天应用”的关键
你只要做到：
- 生成输出里返回引用 chunk 的 `id/source/title`
- UI 展示引用片段（可展开）
就能大幅提升可信度，也让你能调试“召回是否正确”。

#### C6. RAG 的典型坑（提前知道就赢一半）
- 噪声召回：同名地点/简称 → 用元数据过滤 + 候选确认
- 冲突知识：不同笔记观点不同 → 输出冲突并提示“按当前条件选 A/B”
- 指令污染：检索内容夹带“忽略规则” → 明确“文档是内容不是指令” + 工具层兜底

---

### 附录 D：评估与回归（把效果变成事实）

#### D1. 为什么评估是“入门门槛”，不是“高级选修”
没有评估，你的迭代是玄学：
- 改 prompt 可能变好也可能变坏，你不知道
- 加工具/加 RAG 后，失败率/延迟/成本可能飙升，你不知道

#### D2. 用例集（Test Set）怎么做才有用
你的用例集要覆盖“分支”，不是覆盖“内容”：
- 有 GPS / 无 GPS
- 候选地点用户确认 是 / 否
- 地图搜索一击命中 / 歧义多个候选
- 小红书风 / 旅行日志
- 多地点多照片

每条用例最少记录：
- 输入摘要（可以不存真实照片，存 EXIF 抽取结果/描述）
- 期望结构（字段必须齐全）
- 容许差异（文案可变，但要点必须覆盖）

#### D3. 三类指标（你要能背出来并解释）
可靠性：
- schema 通过率、工具失败率、重试次数、降级次数

体验：
- 首 token 时间、总耗时、用户确认步数、中断率

成本：
- token 数、缓存命中率、外部 API 次数、按用户/按功能统计

#### D4. 回归自动化（从轻到重）
轻量（你现在就能做）：
- 发送固定输入 → 验证 schema + 关键字段存在 + 引用非空

中等（求职很加分）：
- 对“结构化输出字段”做 diff（比较 v1/v2 的覆盖率）

更重（以后再做）：
- LLM-as-judge：让模型按标准打分（需要防偏差与校准）

---

### 附录 E：Agent 设计模式（你会在文章里反复看到的“套路”）

#### E1. ReAct（思考/行动交替）的工程化版本
要点：每一步只做一件事（问用户/调工具/产出结构化结果），不要让模型“一次做完所有事”。
落地：你用状态机限制步数与动作类型，避免无限循环。

#### E2. Plan-and-Execute（先计划后执行）
适合复杂任务，但注意：
- “计划”必须可执行、可分步验证
- 计划不是越长越好，长计划经常是幻觉

在 PhotoCoach 里，计划可以非常短：
- “先提取 EXIF → 如果有 GPS 就逆地理 → 否则给候选并让用户确认 → 最后生成总结”

#### E3. 人机协作（Human-in-the-loop）是产品化的关键
你做“确认点”越清晰，Agent 就越可靠：
- 候选地点列表由用户点选（比模型自己拍板靠谱）
- 生成的 Markdown 让用户编辑（比模型自信输出靠谱）

---

### 附录 F：再多学一点（你未来会用到的“系统级思考”）

#### F1. 采样与确定性：为什么同样输入会得到不同输出
核心参数：
- `temperature`：越高越发散，越低越稳定
- `top_p`：另一种控制随机性的方法

工程建议：
- 结构化输出/工具参数生成：用低温（更稳定）
- 文案创作：可适当提高温度，但外层结构保持稳定

#### F2. 缓存策略：既省钱又提速
适合缓存的东西：
- 逆地理编码结果、地点搜索结果（同一关键词/同一坐标）
- RAG 的检索结果（同一查询）
- 模型输出（同一输入、同一版本、同一参数）

注意：缓存必须带版本号（prompt/schema/tool 变了就要失效）。

#### F3. 多模型路由（你有 GPT/Gemini/Claude 的优势怎么用）
你可以用“路由器思维”：
- 默认用性价比最高的模型
- 结构化校验失败/需要更强推理时升级到更强模型
- 失败则降级（不阻塞用户完成任务）

这件事本质是产品思维：成本与效果的平衡，而不是追求最强模型。

#### F4. 观察性（Observability）：为什么大厂在意
你至少要能回答：
- 这次生成为什么慢？慢在模型还是慢在地图？
- 失败发生在哪一步？重试了几次？用户卡在哪一步？

最小实现：
- 每次请求的 traceId
- 工具调用记录（工具名、参数摘要、耗时、结果摘要、错误码）
- 模型调用记录（耗时、token、版本）

---

